#!/usr/bin/env python3
"""
Extract tables from PDF or Excel to Markdown.
- PDF: pdfplumber
- Excel: pandas (xls/xlsx), multi-sheet, legal annex aware
"""

import argparse
import os
from pathlib import Path

import pdfplumber
import pandas as pd

DOCUMENT_TITLE = ("""Quy·∫øt ƒë·ªãnh 7603/Qƒê-BYT nƒÉm 2018 v·ªÅ B·ªô m√£ danh m·ª•c d√πng chung √°p d·ª•ng trong qu·∫£n l√Ω kh√°m b·ªánh, ch·ªØa b·ªánh v√† thanh to√°n b·∫£o hi·ªÉm y t·∫ø (phi√™n b·∫£n s·ªë 6) do B·ªô tr∆∞·ªüng B·ªô Y t·∫ø ban h√†nh""")
CHUNK_ROW_SIZE = 30
def chunk_rows(rows: list, chunk_size: int):
    for i in range(0, len(rows), chunk_size):
        yield rows[i:i + chunk_size]

# ==========================================================
# COMMON UTILITIES
# ==========================================================
def extract_annex_title(df, max_rows=6):
    """
    Extract annex title from top rows (merged cells).
    """
    lines = []
    for i in range(min(len(df), max_rows)):
        row = df.iloc[i]
        values = [str(c).strip() for c in row if pd.notna(c)]
        if values:
            lines.append(" ".join(values))

    text = " ".join(lines)
    text = " ".join(text.split())
    return text if len(text) > 20 else None


def detect_header_row(df, scan_rows=20):
    """
    Robust header detection for legal Excel:
    1. Any cell CONTAINS 'STT'
    2. Fallback: row index 1 or 2
    3. Fallback: dense string row
    """

    # -------- TIER 1: regex STT --------
    for i in range(min(len(df), scan_rows)):
        row = df.iloc[i]
        for cell in row:
            if pd.notna(cell):
                text = str(cell).strip().upper()
                if "STT" in text:
                    return i

    # -------- TIER 2: fixed position --------
    for i in (1, 2):
        if i < len(df):
            row = df.iloc[i]
            non_empty = sum(
                1 for c in row
                if pd.notna(c) and str(c).strip() != ""
            )
            if non_empty >= 3:
                return i

    # -------- TIER 3: density heuristic --------
    for i in range(min(len(df), scan_rows)):
        row = df.iloc[i]
        texts = [
            c for c in row
            if pd.notna(c)
            and isinstance(c, str)
            and len(c.strip()) > 1
        ]
        if len(texts) >= 3:
            return i

    return None

def normalize_cell_text(value):
    """
    Chu·∫©n h√≥a n·ªôi dung trong 1 √¥ Excel:
    - G·ªôp c√°c d√≤ng trong √¥ th√†nh 1 d√≤ng
    - X√≥a kho·∫£ng tr·∫Øng th·ª´a
    """
    if pd.isna(value):
        return ""

    text = str(value)

    # thay xu·ªëng d√≤ng, tab b·∫±ng kho·∫£ng tr·∫Øng
    text = text.replace("\r", " ").replace("\n", " ").replace("\t", " ")

    # gom nhi·ªÅu space th√†nh 1
    text = " ".join(text.split())

    return text

# ==========================================================
# PDF HANDLER
# ==========================================================
def extract_tables_from_pdf(pdf_path: str, output_path: str = None,
                            start_page: int = 1, end_page: int = None):

    if not os.path.exists(pdf_path):
        print(f"‚ùå PDF not found: {pdf_path}")
        return

    if output_path is None:
        output_path = os.path.splitext(pdf_path)[0] + "_tables.md"

    with pdfplumber.open(pdf_path) as pdf:
        total_pages = len(pdf.pages)
        start_idx = start_page - 1
        end_idx = end_page if end_page else total_pages

        print(f"üìÑ PDF: {pdf_path}")
        print(f"üìù Output: {output_path}")
        print(f"üìä Pages {start_page} ‚Üí {end_idx}")
        print("=" * 60)

        mode = 'a' if start_page > 1 else 'w'

        with open(output_path, mode, encoding="utf-8") as f:
            # if mode == 'w':
            #     f.write(f"# Tables extracted from {os.path.basename(pdf_path)}\n\n")

            table_count = 0
            for page_num in range(start_idx, end_idx):
                page = pdf.pages[page_num]
                tables = page.extract_tables()

                if not tables:
                    continue

                for table in tables:
                    if not table or len(table) < 2:
                        continue

                    f.write(f"\n<!-- Page {page_num + 1} -->\n")

                    header = table[0]
                    f.write("| " + " | ".join(str(c or "").replace("\n", " ") for c in header) + " |\n")
                    f.write("|" + "|".join(["---"] * len(header)) + "|\n")

                    for row in table[1:]:
                        f.write("| " + " | ".join(str(c or "").replace("\n", " ") for c in row) + " |\n")

                    table_count += 1

        print(f"‚úÖ Done! Extracted {table_count} tables")
        print(f"üìù Saved to: {output_path}")


# ==========================================================
# EXCEL HANDLER (LEGAL ANNEX AWARE)
# ==========================================================
def extract_tables_from_excel_folder(input_folder: str, output_folder: str = None):
    input_path = Path(input_folder)

    if not input_path.exists():
        print(f"‚ùå Folder not found: {input_folder}")
        return

    output_folder = Path(output_folder) if output_folder else input_path / "output_txt"
    output_folder.mkdir(parents=True, exist_ok=True)

    excel_files = list(input_path.glob("*.xls")) + list(input_path.glob("*.xlsx"))

    print(f"üìÇ Excel folder: {input_folder}")
    print(f"üìù Output folder: {output_folder}")
    print(f"üìä Found {len(excel_files)} Excel files")
    print("=" * 60)

    for excel_file in excel_files:
        print(f"üìÑ Processing: {excel_file.name}")
        out_file = output_folder / f"{excel_file.stem}.txt"

        try:
            sheets_raw = pd.read_excel(
                excel_file,
                sheet_name=None,
                header=None
            )
        except Exception as e:
            print(f"‚ùå Failed to read {excel_file.name}: {e}")
            continue

        with open(out_file, "w", encoding="utf-8") as f:
            # f.write(f"# Tables extracted from {excel_file.name}\n\n")

            for sheet_name, raw_df in sheets_raw.items():
                if raw_df.empty:
                    continue

                # 1. Annex title
                annex_title = extract_annex_title(raw_df)

                # 2. Detect header
                header_row = detect_header_row(raw_df)
                if header_row is None:
                    print(f"‚ö†Ô∏è No header detected: {excel_file.name} / {sheet_name}")
                    continue

                # 3. Build dataframe
                df = raw_df.iloc[header_row + 1:].copy()
                df.columns = raw_df.iloc[header_row].astype(str).str.strip()
                df = df.reset_index(drop=True)

                # drop empty / unnamed columns
                df = df.loc[:, ~df.columns.str.contains("^Unnamed")]
                df = df.applymap(normalize_cell_text)
                if df.empty:
                    continue
                # 4. Write chunks (CHU·∫®N LLM)
                headers = df.columns.tolist()
                rows = df.values.tolist()

                row_chunks = list(chunk_rows(rows, CHUNK_ROW_SIZE))

                for idx, chunk in enumerate(row_chunks):
                    # ===== 1. TITLE CHUNG C·ª¶A VƒÇN B·∫¢N =====
                    f.write(DOCUMENT_TITLE.strip() + "\n")
                    # ===== 2. T√äN PH·ª§ L·ª§C =====
                    if annex_title:
                        f.write(annex_title.strip() + "\n")
                    # ===== 3. HEADER =====
                    f.write("| " + " | ".join(headers) + " |\n")
                    f.write("|" + "|".join(["---"] * len(headers)) + "|\n")
                    # ===== 4. N·ªòI DUNG =====
                    for row in chunk:
                        f.write("| " + " | ".join(map(str, row)) + " |\n")
                    # ===== 5. D√íNG TR·ªêNG GI·ªÆA C√ÅC CHUNK =====
                    if not (
                        sheet_name == list(sheets_raw.keys())[-1]
                        and idx == len(row_chunks) - 1
                    ):
                        f.write("\n")
        print(f"‚úÖ Saved: {out_file}")

    print("\nüéâ Done extracting Excel tables!")


# ==========================================================
# CLI
# ==========================================================
def main():
    parser = argparse.ArgumentParser(
        description="Extract tables from PDF or Excel to Markdown (legal annex aware)"
    )

    subparsers = parser.add_subparsers(dest="mode", required=True)

    # PDF
    pdf_parser = subparsers.add_parser("pdf", help="Extract tables from PDF")
    pdf_parser.add_argument("pdf_path")
    pdf_parser.add_argument("-o", "--output")
    pdf_parser.add_argument("-s", "--start", type=int, default=1)
    pdf_parser.add_argument("-e", "--end", type=int)

    # EXCEL
    excel_parser = subparsers.add_parser("excel", help="Extract tables from Excel folder")
    excel_parser.add_argument("folder", help="Folder containing xls/xlsx files")
    excel_parser.add_argument("-o", "--output", help="Output folder")

    args = parser.parse_args()

    if args.mode == "pdf":
        extract_tables_from_pdf(
            args.pdf_path, args.output, args.start, args.end
        )
    elif args.mode == "excel":
        extract_tables_from_excel_folder(
            args.folder, args.output
        )


if __name__ == "__main__":
    main()
